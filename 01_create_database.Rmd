Create and Fill Database
========================

We store Meta information fo GEO samples and BioQC results in 
a postgreSQL database. In this document, we initalize the
database with the metadata. 

The sql schemata can be found in `db/*.sql`. 

```{r}
stop("This file is not intended to be ran as a script. This would mess up the database. ")
source("lib/db.R")
source("lib/lib.R")
source("lib/geo_annotation.R")
source("lib/db_io.R")
library(RSQLite)
library(testthat)
library(data.table)
library(readxl)
```

Convert GEOMetadb
-----------------

[GEOMetabase](https://www.bioconductor.org/packages/release/bioc/vignettes/GEOmetadb/inst/doc/GEOmetadb.html) 
is an sqlite database containing all the meta information also stored in the ExpressionSets. 
There is a shell script `db/sqlite_to_psql.sh` that converts the sqlite database into a postgresql database. 
A nasty file system/kernel bug lead to random skipping of rows, which I had to find a workaround to. 

We first need to provide a list of tables: 
```{r}
gdb = dbConnect(SQLite(), "db/geometabase/GEOmetadb.sqlite")
tables = dbListTables(gdb)
writeLines(tables, file("db/geometabase/tables.txt"))
```

Truncate previous data (uncomment corresponding line): 
```{r}
for(table in tables) {
#    dbSendUpdate(mydb, sprintf("truncate %s cascade", tolower(table)))
}
```

Then, we run the shell script `db/sqlite_to_psql` to import the data. All corresponding steps are documented in the shell script. 
It involves charset conversion and workarounds around the filesystem bug. 
The following chunk can be used to find what rows have been skipped in the gsm table and debug the conversion process. 
```{r}
in.sqlite = dbGetQuery(gdb, "select gsm from gsm order by gsm")
in.psql = dbGetQuery(mydb, "select gsm from gsm order by gsm")
writeLines(in.sqlite[[1]], file("db/in.sqlite.txt"))
writeLines(in.sqlite[[1]], file("db/in.psql.txt"))
```

Now, check for consistency, i.e. do all tables have the same number of rows? 
```{r}
# check for consistency 
for(table in tables) {
  count.query = sprintf("select count(*) from %s", table)
  count.query.ora = sprintf("select count(*) from bioqc_%s", table)
  print(count.query)
  expect_equal(dbGetQuery(gdb, count.query)[[1]], dbGetQuery(mydb, tolower(count.query.ora))[[1]])
}
```

### Load annotation information

To run BioQC, we need the Gene Symbols to be annotated. For this, we have essentially two possibilities: 

* use the Bioconductor annotation packages (listed in GeometaDB `gpl.bioc_package`)
* use the GEO annot_gpl files ("in general available for all GSE that are referenced by a GDS"[^1]) 

[^1]: https://bioconductor.org/packages/release/bioc/manuals/GEOquery/man/GEOquery.pdf

To find out for which GSE in particular the latter option exists, we retrieved the directory structure of the 
GEO ftp server: 

* `lftp -c "open ftp://ftp.ncbi.nlm.nih.gov/geo/platforms/ && find && exit" > gpl_annot_ftp_tree.txt` 
* `grep annot.gz gpl_annot_ftp_tree.txt | cut -d"/" -f5 | cut -d"." -f1 > gpl_annot.txt`

We store a boolean flag in the gpl table if the respective platform provides an annotation file. 

```{r}
sql = "create table bioqc_gpl_annot(gpl varchar2(10) primary key, has_annot number(1))"
dbSendUpdate(mydb, sql)
annot = read.table("db/data/gpl_annot.txt")
annot = cbind(annot, rep(1, length(annot)))
colnames(annot) = c("1", "2")
dbAppendDf("BIOQC_GPL_ANNOT", annot)
sqlUpdateGpl = "
  update bioqc_gpl g
  set has_annot = (select has_annot from bioqc_gpl_annot a
                     where g.gpl = a.gpl)"
dbSendUpdate(mydb, sqlUpdateGpl)
```


Insert inital data
------------------

### Signatures

Import signatures into the database and create a single, consolidated gmt file. 
```{r}
download.file("http://bioinfo.bas.roche.com:8080/apps/gsea/genesets/exp.tissuemark.bioqc.roche.symbols.gmt",
              "data/expr.tissuemark.affy.roche.symbols.gmt")
gmt2db("data/expr.tissuemark.affy.roche.symbols.gmt")
gmt2db("../BioQC_correlated-pathways/go.bp.roche.symbols.gmt.uniq")
gmt2db("../BioQC_correlated-pathways/MetaBase.downstream.expression.gmt")
gmt2db("../BioQC_correlated-pathways/path.ronet.roche.symbols.gmt.ascii")
gmt2db("../gene-set-study/data/gtex/gtex_ngs_0.7_3.gmt")
gmt2db("../gene-set-study/data/gtex/gtex_ngs_0.85_5.gmt")
db2gmt("results/gmt_all.gmt")
```


### Tissues

The tissue table is a.t.m essintially a list of tissues that we curated. 
For these tissues we created a map from the original GEO annotation to a 
unified tissue name that we can work with. 
```{r}
normalized_tissues = data.table(read_excel("manual_annotation/normalize_tissues.xlsx"))
tissues = unique(normalized_tissues[!is.na(TISSUE_NORMALIZED),"TISSUE_NORMALIZED", with=FALSE])
tab_normalized = normalized_tissues[!is.na(TISSUE_NORMALIZED),c("TISSUE", "TISSUE_NORMALIZED"), with=FALSE]

dbAppendDf("BIOQC_TISSUES", tissues)
dbAppendDf("BIOQC_NORMALIZE_TISSUES", tab_normalized)

```

### Map signatures to tissues

To decide about contaminations, we need to know to which tissue each siganture belongs. 
We annotated this manually in a csv file for the most common tissues and now load it into the database. 
We minted a notion called 'tissue set'. A tissue set, e.g. 'intestine' is a superterm of 'colon' and 'jejunum' and will contain all 'expected signatures' for colon and jejunum. 
```{r}
bioqc_solid = read_excel("manual_annotation/signature_sets.xlsx", sheet = 1)
gtex_solid = read_excel("manual_annotation/signature_sets.xlsx", sheet=2)
gtex_all = read_excel("manual_annotation/signature_sets.xlsx", sheet=3)

signatureset2db(bioqc_solid, "bioqc_solid")
signatureset2db(gtex_solid, "gtex_solid")
signatureset2db(gtex_all, "gtex_all")

```



