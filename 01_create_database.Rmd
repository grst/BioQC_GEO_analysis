Create and Fill Database
========================

We store Meta information fo GEO samples and BioQC results in 
a postgreSQL database. In this document, we initalize the
database with the metadata. 

The sql schemata can be found in `db/*.sql`. 

```{r}
stop("This file is not intended to be ran as a script. This would mess up the database. ")
source("lib/db.R")
source("lib/lib.R")
source("lib/geo_annotation.R")
library(RSQLite)
library(testthat)
library(data.table)
```

Convert GEOMetadb
-----------------

[GEOMetabase](https://www.bioconductor.org/packages/release/bioc/vignettes/GEOmetadb/inst/doc/GEOmetadb.html) 
is an sqlite database containing all the meta information also stored in the ExpressionSets. 
There is a shell script `db/sqlite_to_psql.sh` that converts the sqlite database into a postgresql database. 
A nasty file system/kernel bug lead to random skipping of rows, which I had to find a workaround to. 

We first need to provide a list of tables: 
```{r}
gdb = dbConnect(SQLite(), "db/geometabase/GEOmetadb.sqlite")
tables = dbListTables(gdb)
writeLines(tables, file("db/geometabase/tables.txt"))
```

Truncate previous data (uncomment corresponding line): 
```{r}
for(table in tables) {
#    dbSendUpdate(mydb, sprintf("truncate %s cascade", tolower(table)))
}
```

Then, we run the shell script `db/sqlite_to_psql` to import the data. All corresponding steps are documented in the shell script. 
It involves charset conversion and workarounds around the filesystem bug. 
The following chunk can be used to find what rows have been skipped in the gsm table and debug the conversion process. 
```{r}
in.sqlite = dbGetQuery(gdb, "select gsm from gsm order by gsm")
in.psql = dbGetQuery(mydb, "select gsm from gsm order by gsm")
writeLines(in.sqlite[[1]], file("db/in.sqlite.txt"))
writeLines(in.sqlite[[1]], file("db/in.psql.txt"))
```

Now, check for consistency, i.e. do all tables have the same number of rows? 
```{r}
# check for consistency 
for(table in tables) {
  count.query = sprintf("select count(*) from %s", table)
  print(count.query)
  expect_equal(dbGetQuery(gdb, count.query)[[1]], dbGetQuery(mydb, tolower(count.query))[[1]])
}
```


Insert inital data
------------------

### Tissues

The tissue table is a.t.m essintially a list of tissues that we curated. 
For these tissues we created a map from the original GEO annotation to a 
unified tissue name that we can work with. 
```{r}
dbAppendDf("bioqc_tissues", unique(geo_annotation.tissueMap["tissue"]))
dbSendUpdate(mydb, "insert into bioqc_tissues values('other')")
```


### Signatures

Import the list of BioQC signatures from the gmt file shipped with the BioQC package. 
```{r}
library(BioQC)
gmtFile = system.file("extdata/exp.tissuemark.affy.roche.symbols.gmt", package="BioQC")
gmt <- readGmt(gmtFile)
gmt.list = lapply(gmt, function(line) {
  return(list(name=line$name, desc=line$desc, genes=paste(line$genes, collapse=',')))
})
gmt.table = do.call(rbind.data.frame, gmt.table)
dbAppendDf("bioqc_signatures", gmt.table)
```


### Sample tissue annotation 

The sample tissue annotation is provided by GEOmetabase, however it is hidden in the `characertistics_ch1` column. 
We extract the information from there and put it into a new column. This is more convenient and indexable. 
```{r}
extractTissue = function(x) {extractFromList(x, 'tissue:')}
tissue.raw = dbGetQuery(mydb, "select gsm, characteristics_ch1 from gsm where characteristics_ch1 like '%tissue: %'")
tissues.extracted = lapply(tissue.raw$characteristics_ch1, extractTissue)
tissues = lapply(tissues.extracted, sanitizeTissue)
dbSendUpdate(mydb, "create temp table bioqc_gsm(gsm varchar(10), tissue varchar(80), tissue_orig text)")
table = cbind(gsm=tissue.raw$gsm, tissue=tissues, tissue_orig=tissues.extracted)
dbAppendDf("bioqc_gsm", table)
sqlUpdateGsm = "
  update gsm
  set tissue = bioqc_gsm.tissue, tissue_orig = bioqc_gsm.tissue_orig
  from bioqc_gsm
  where gsm.gsm = bioqc_gsm.gsm"
dbSendUpdate(mydb, sqlUpdateGsm)
```


### Map signatures to tissues

To decide about contaminations, we need to know to which tissue each siganture belongs. 
We annotated this manually in a csv file for the most common tissues and now load it into the database. 
```{r}
sig.tissue.map = read.table("lib/res/map_signature_tissue.csv", sep=";")
sig.tissue.map = sig.tissue.map[sig.tissue.map$V2!="",]
sig.tissue.map = sig.tissue.map[,c(2,1)]
dbAppendDf("bioqc_tissues_signatures", sig.tissue.map)
```

### Load annotation information

To run BioQC, we need the Gene Symbols to be annotated. For this, we have essentially two possibilities: 

* use the Bioconductor annotation packages (listed in GeometaDB `gpl.bioc_package`)
* use the GEO annot_gpl files ("in general available for all GSE that are referenced by a GDS"[^1]) 

[^1]: https://bioconductor.org/packages/release/bioc/manuals/GEOquery/man/GEOquery.pdf

To find out for which GSE in particular the latter option exists, we retrieved the directory structure of the 
GEO ftp server: 

* `lftp -c "open ftp://ftp.ncbi.nlm.nih.gov/geo/platforms/ && find && exit" > gpl_annot_ftp_tree.txt` 
* `grep annot.gz gpl_annot_ftp_tree.txt | cut -d"/" -f5 | cut -d"." -f1 > gpl_annot.txt`

We store a boolean flag in the gpl table if the respective platform provides an annotation file. 

```{r}
sql = "create temp table bioqc_gpl_annot(gpl varchar(10) primary key, has_annot int);"
dbSendUpdate(mydb, sql)
annot = read.table("db/data/gpl_annot.txt")
annot = cbind(annot, rep(1, length(annot)))
colnames(annot) = c("1", "2")
dbAppendDf("bioqc_gpl_annot", annot)
sqlUpdateGpl = "
  update gpl
  set has_annot = TRUE
  from bioqc_gpl_annot a 
  where a.gpl = gpl.gpl and a.has_annot = 1"
dbSendUpdate(mydb, sqlUpdateGpl)
```

