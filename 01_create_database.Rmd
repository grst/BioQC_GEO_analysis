Create and Fill Database
========================

We store Meta information fo GEO samples and BioQC results in 
a postgreSQL database. In this document, we initalize the
database with the metadata. 

The sql schemata can be found in `db/*.sql`. 

```{r}
source("lib/db.R")
source("lib/lib.R")
source("lib/geo_annotation.R")
library(RSQLite)
library(testthat)
library(data.table)
```

Convert GEOMetadb
-----------------

[GEOMetabase](https://www.bioconductor.org/packages/release/bioc/vignettes/GEOmetadb/inst/doc/GEOmetadb.html) 
is an sqlite database containing all the meta information also stored in the ExpressionSets. 
There is a shell script `db/sqlite_to_psql.sh` that converts the sqlite database into a postgresql database. 
A nasty file system/kernel bug lead to random skipping of rows, which I had to find a workaround to. 

We first need to provide a list of tables: 
```{r}
gdb = dbConnect(SQLite(), "db/geometabase/GEOmetadb.sqlite")
tables = dbListTables(gdb)
writeLines(tables, file("db/geometabase/tables.txt"))
```

Truncate previous data (uncomment corresponding line): 
```{r}
for(table in tables) {
#    dbSendUpdate(mydb, sprintf("truncate %s cascade", tolower(table)))
}
```

Then, we run the shell script `db/sqlite_to_psql` to import the data. All corresponding steps are documented in the shell script. 
It involves charset conversion and workarounds around the filesystem bug. 
The following chunk can be used to find what rows have been skipped in the gsm table and debug the conversion process. 
```{r}
in.sqlite = dbGetQuery(gdb, "select gsm from gsm order by gsm")
in.psql = dbGetQuery(mydb, "select gsm from gsm order by gsm")
writeLines(in.sqlite[[1]], file("db/in.sqlite.txt"))
writeLines(in.sqlite[[1]], file("db/in.psql.txt"))
```

Now, check for consistency, i.e. do all tables have the same number of rows? 
```{r}
# check for consistency 
for(table in tables) {
  count.query = sprintf("select count(*) from %s", table)
  print(count.query)
  expect_equal(dbGetQuery(gdb, count.query)[[1]], dbGetQuery(mydb, tolower(count.query))[[1]])
}
```


Insert inital data
------------------

### Tissues

The tissue table is a.t.m essintially a list of tissues that we curated. 
For these tissues we created a map from the original GEO annotation to a 
unified tissue name that we can work with. 
```{r}
dbAppendDf("bioqc_tissues", unique(geo_annotation.tissueMap["tissue"]))
dbSendUpdate(mydb, "insert into bioqc_tissues values('other')")
```


### Signatures

Import the list of BioQC signatures from the gmt file shipped with the BioQC package. 
```{r}
library(BioQC)
gmtFile = system.file("extdata/exp.tissuemark.affy.roche.symbols.gmt", package="BioQC")
gmt <- readGmt(gmtFile)
gmt.list = lapply(gmt, function(line) {
  return(list(name=line$name, desc=line$desc, genes=paste(line$genes, collapse=',')))
})
gmt.table = do.call(rbind.data.frame, gmt.table)
dbAppendDf("bioqc_signatures", gmt.table)
```


### Extended sample meta information

The meta information is already provided by GEOmetabase. However, we want to add additional metadata 
in a separate table, e.g extracted tissue annotation. 
```{r}
extractTissue = function(x) {extractFromList(x, 'tissue:')}
tissue.raw = dbGetQuery(mydb, "select gsm, characteristics_ch1 from gsm where characteristics_ch1 like '%tissue: %'")
tissues.extracted = lapply(tissue.raw$characteristics_ch1, extractTissue)
tissues = lapply(tissues.extracted, sanitizeTissue)
table = cbind(gsm=tissue.raw$gsm, tissue=tissues, tissue_orig=tissues.extracted)
dbAppendDf("bioqc_gsm", table)
```


### Map signatures to tissues

To decide about contaminations, we need to know to which tissue each siganture belongs. 
We annotated this in a csv file and now load it into the database. 
```{r}
sig.tissue.map = read.table("lib/res/map_signature_tissue.csv", sep=";")
sig.tissue.map = sig.tissue.map[sig.tissue.map$V2!="",]
sig.tissue.map = sig.tissue.map[,c(2,1)]
dbAppendDf("bioqc_tissues_signatures", sig.tissue.map)
```

### Load annotation information
The directory structure of the GEO platforms was downloaded in order to find out, which GPL's provide annotation
information. 

* `lftp -c "open ftp://ftp.ncbi.nlm.nih.gov/geo/platforms/ && find && exit" > gpl_annot_ftp_tree.txt` 
* `grep annot.gz gpl_annot_ftp_tree.txt | cut -d"/" -f5 | cut -d"." -f1 > gpl_annot.txt`

```{r}
sql = "create table bioqc_gpl_annot(gpl varchar(10) primary key references gpl(gpl), has_annot bool);"
dbSendUpdate(mydb, sql)
annot = read.table("db/data/gpl_annot.txt")
annot = cbind(annot, rep(1, length(annot)))
colnames(annot) = c("1", "2")
dbAppendDf("bioqc_gpl_annot", annot)
```



Load BioQC data into the database
---------------------------------

We now need to fill the table with the BioQC results. There is a separate R script for that:
`scripts/bioqc2db.R`


